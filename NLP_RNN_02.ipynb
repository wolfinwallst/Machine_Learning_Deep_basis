{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wolfinwallst/Machine_Learning_Deep_basis/blob/main/NLP_RNN_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFsXyGLoth0P"
      },
      "source": [
        "문자 레벨 RNN (character-level RNN): RNN의 입출력 단위가 단어 레벨 (word-level)이 아닌 문자 레벨인 경우\n",
        "\n",
        "`Char RNN`\n",
        "\n",
        "아래에선, 문자 단위 RNN을 다대다 구조로 구현한다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CwZoRpqWth0R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "문자 시퀀스 apple을 입력받으면 pple!를 출력하는 RNN을 구현해보자:"
      ],
      "metadata": {
        "id": "Hp9xFH6tGf42"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPRRMrD3th0S",
        "outputId": "6ee3b9c8-ebc5-43ae-dd9e-790b69fdf4c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합의 크기 : 5\n"
          ]
        }
      ],
      "source": [
        "input_str = 'apple'\n",
        "label_str = 'pple!'\n",
        "\n",
        "# 입력 데이터와 레이블 데이터에서 중복을 제거한 문자들의 집합인 문자 집합(vocabulary)을 생성한다\n",
        "char_vocab = sorted(list(set(input_str + label_str)))\n",
        "vocab_size = len(char_vocab)\n",
        "\n",
        "print('문자 집합의 크기 : {}'.format(vocab_size))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(char_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_87y47cGppL",
        "outputId": "ece6c537-062e-4983-f7d0-280ac5411eaf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['!', 'a', 'e', 'l', 'p']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "s3nqVo8Nth0S"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "\n",
        "# 입력 크기는 문자 집합의 크기 (입력은 1-hot 벡터를 사용할 예정이므로 이렇게 설정)\n",
        "input_size = vocab_size\n",
        "hidden_size = 5\n",
        "output_size = 5\n",
        "learning_rate = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자 집합에 고유한 정수를 부여\n",
        "char_to_index = dict((c, i) for i, c in enumerate(char_vocab))\n",
        "print(char_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKwY50-StmFd",
        "outputId": "82bc6ae0-23e2-41de-b9ed-b9f33b67793f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'!': 0, 'a': 1, 'e': 2, 'l': 3, 'p': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UktDbCJlLvyO",
        "outputId": "5441ee38-2b80-4d68-a23f-e03ccfbd4e43"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('!', 0), ('a', 1), ('e', 2), ('l', 3), ('p', 4)])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 나중에 예측 결과를 다시 문자 시퀀스로 보기위해서\n",
        "# 반대로 정수로부터 문자를 얻을 수 있는 index_to_char을 만든다.\n",
        "index_to_char = {}\n",
        "for key, value in char_to_index.items():\n",
        "    index_to_char[value] = key\n",
        "\n",
        "print(index_to_char)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gts9mZktmmS",
        "outputId": "59cd7af0-5cd8-47dc-d702-30d0bdbf2bd2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: '!', 1: 'a', 2: 'e', 3: 'l', 4: 'p'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력/레이블 데이터의 각 문자들을 정수로 맵핑\n",
        "x_data = [char_to_index[c] for c in input_str]\n",
        "y_data = [char_to_index[c] for c in label_str]\n",
        "\n",
        "print(x_data)\n",
        "print(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFev4j3su4Mq",
        "outputId": "526d2b08-3b59-4b14-dc05-1a2bc0b55f87"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 4, 3, 2]\n",
            "[4, 4, 3, 2, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFYa0Xgmth0S",
        "outputId": "c7ad28e8-567d-46b5-86e3-088ae4ca71c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 4, 4, 3, 2]]\n",
            "[[4, 4, 3, 2, 0]]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "PyTorch의 nn.RNN()은 기본적으로 3차원 텐서를 입력받으므로 배치 차원을 추가해주자\n",
        "\"\"\"\n",
        "# 텐서 연산인 unsqueeze(0)를 통해 해결할 수도 있다.\n",
        "x_data = [x_data]\n",
        "y_data = [y_data]\n",
        "\n",
        "print(x_data)\n",
        "print(y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvwsDexFth0T",
        "outputId": "af3f3090-6076-43b5-a45e-896cd80173d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[0., 1., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 1.],\n",
            "       [0., 0., 0., 0., 1.],\n",
            "       [0., 0., 0., 1., 0.],\n",
            "       [0., 0., 1., 0., 0.]])]\n"
          ]
        }
      ],
      "source": [
        "# [one-hot encoding 구현 트릭] 이니 기억해두자!\n",
        "\n",
        "# vocab_size = 5 로 위에서 설정했다.\n",
        "\"\"\"\n",
        "입력 시퀀스의 각 문자들을 원-핫 벡터로 변환\n",
        "x_data에 있는 각 값 x를 one-hot encoding 형태로 변환\n",
        "\n",
        "vocab_size x vocab_size 크기의 단위 행렬의 x 번째 행을 선택\n",
        "\"\"\"\n",
        "x_one_hot = [np.eye(vocab_size)[x] for x in x_data] # np.eye(n) 으로 n x n 단위행렬 생성\n",
        "print(x_one_hot)\n",
        "\n",
        "# x_data 와 비교하면 같은 위치에만 1이고 따라서 x_one_hot이 x_data의 원-핫 인코딩임을 알 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CYJ9tdvth0T",
        "outputId": "e7118218-2f8a-49d7-82c0-9566dd5fd26c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기 : torch.Size([1, 5, 5])\n",
            "레이블 데이터의 크기 : torch.Size([1, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-4f1afd07e5bb>:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  X = torch.FloatTensor(x_one_hot)\n"
          ]
        }
      ],
      "source": [
        "# 입력 데이터와 레이블 데이터를 텐서로 바꾼다.\n",
        "X = torch.FloatTensor(x_one_hot)\n",
        "Y = torch.LongTensor(y_data)\n",
        "\n",
        "print('훈련 데이터의 크기 : {}'.format(X.shape))\n",
        "print('레이블 데이터의 크기 : {}'.format(Y.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 RNN 모델을 구현한다:"
      ],
      "metadata": {
        "id": "o0DlYRvkwitX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN 모델을 구현하는 클래스\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn = torch.nn.RNN(input_size, hidden_size, batch_first=True) # RNN 셀\n",
        "        self.fc = torch.nn.Linear(hidden_size, output_size, bias=True) # 출력층\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _status = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "fgK7-hcUwYnU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWeaAPIYth0T",
        "outputId": "16859c3b-26f6-4e40-ed52-27a8b18ef43b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (rnn): RNN(5, 5, batch_first=True)\n",
            "  (fc): Linear(in_features=5, out_features=5, bias=True)\n",
            ")\n",
            "torch.Size([1, 5, 5])\n"
          ]
        }
      ],
      "source": [
        "net = Net(input_size, hidden_size, output_size)\n",
        "print(net)\n",
        "\n",
        "outputs = net(X)\n",
        "print(outputs.shape) # 3D 텐서 (배치 차원, 시점(timesteps), 출력 크기)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "나중에 정확도를 측정할 때, 이를 모두 펼쳐서 계산하게 되는데,\n",
        "이때는 view를 사용하여 배치 차원과 시점 차원을 하나로 만든다.\n",
        "\"\"\"\n",
        "print(outputs.view(-1, input_size).shape) # 2D 텐서로 변환"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4u5y4lQzUTT",
        "outputId": "16e14bf5-0425-4acd-d04e-3121dfcb8006"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "마찬가지로 나중에 정확도를 측정할 때는 이걸 펼쳐서 계산할 예정\n",
        "\"\"\"\n",
        "# 레이블 데이터의 크기\n",
        "print(Y.shape)\n",
        "print(Y.view(-1).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAIQa5rAz9LU",
        "outputId": "e98e7179-f798-4d61-aa50-e744b632f5e6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5])\n",
            "torch.Size([5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "nTQySUigz0Bi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "\n",
        "for i in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    loss = criterion(outputs.view(-1, input_size), Y.view(-1)) # view를 하는 이유는 Batch 차원 제거를 위해\n",
        "    loss.backward() # 기울기 계산\n",
        "    optimizer.step() # 아까 optimizer 선언 시 넣어둔 파라미터 업데이트\n",
        "\n",
        "    # 아래 세 줄은 모델이 실제 어떻게 예측했는지를 확인하기 위한 코드.\n",
        "    result = outputs.data.numpy().argmax(axis=2) # 최종 예측값인 각 time-step 별 5차원 벡터에 대해서 가장 높은 값의 인덱스를 선택\n",
        "    result_str = ''.join([index_to_char[c] for c in np.squeeze(result)]) # squeeze()로 result중 크기가 1인 차원(axis)을 자동으로 제거\n",
        "    print(i, \"loss: \", loss.item(), \"prediction: \", result, \"true Y: \", y_data, \"prediction str: \", result_str)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mipQb6Pxz0PU",
        "outputId": "7dfc6080-e7fb-4bc8-d45a-9e00832a48d9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 loss:  1.6339318752288818 prediction:  [[1 4 4 1 1]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  appaa\n",
            "1 loss:  1.3643710613250732 prediction:  [[4 4 4 2 4]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pppep\n",
            "2 loss:  1.1675583124160767 prediction:  [[4 4 4 2 4]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pppep\n",
            "3 loss:  0.9615438580513 prediction:  [[4 4 4 2 4]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pppep\n",
            "4 loss:  0.7863997220993042 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "5 loss:  0.6365571618080139 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "6 loss:  0.4991140365600586 prediction:  [[4 4 4 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pppe!\n",
            "7 loss:  0.3859456479549408 prediction:  [[4 4 4 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pppe!\n",
            "8 loss:  0.27646633982658386 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "9 loss:  0.20868992805480957 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "10 loss:  0.15444611012935638 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "11 loss:  0.10833491384983063 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "12 loss:  0.08307481557130814 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "13 loss:  0.055443812161684036 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "14 loss:  0.03819730132818222 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "15 loss:  0.02915850281715393 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "16 loss:  0.02219412475824356 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "17 loss:  0.01640504039824009 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "18 loss:  0.012445999309420586 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "19 loss:  0.010173189453780651 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "20 loss:  0.008766241371631622 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "21 loss:  0.007492984179407358 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "22 loss:  0.006174114067107439 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "23 loss:  0.005009383894503117 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "24 loss:  0.004140125587582588 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "25 loss:  0.003545572515577078 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "26 loss:  0.0031358313281089067 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "27 loss:  0.002818275708705187 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "28 loss:  0.002527127740904689 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "29 loss:  0.0022375122644007206 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "30 loss:  0.0019586202688515186 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "31 loss:  0.0017117718234658241 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "32 loss:  0.0015111264074221253 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "33 loss:  0.0013587989378720522 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "34 loss:  0.0012479806318879128 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "35 loss:  0.001168299582786858 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "36 loss:  0.001109227305278182 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "37 loss:  0.0010613215854391456 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "38 loss:  0.0010175409261137247 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "39 loss:  0.0009734582272358239 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "40 loss:  0.00092771538766101 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "41 loss:  0.0008812376181595027 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "42 loss:  0.0008357598562724888 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "43 loss:  0.0007934944587759674 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "44 loss:  0.0007557505159638822 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "45 loss:  0.0007233618525788188 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "46 loss:  0.0006961387116461992 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "47 loss:  0.000673748436383903 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "48 loss:  0.0006552630220539868 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "49 loss:  0.0006397776887752116 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "50 loss:  0.0006263164104893804 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "51 loss:  0.0006141174817457795 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "52 loss:  0.0006024186732247472 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "53 loss:  0.0005909582832828164 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "54 loss:  0.0005793551681563258 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "55 loss:  0.0005677283625118434 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "56 loss:  0.0005561731522902846 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "57 loss:  0.0005449513555504382 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "58 loss:  0.0005342297372408211 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "59 loss:  0.0005242702318355441 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "60 loss:  0.0005150967626832426 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "61 loss:  0.00050685228779912 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "62 loss:  0.0004994415212422609 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "63 loss:  0.0004927930422127247 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "64 loss:  0.0004868116811849177 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "65 loss:  0.00048130686627700925 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "66 loss:  0.00047615947551093996 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "67 loss:  0.0004712265799753368 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "68 loss:  0.00046648448915220797 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "69 loss:  0.00046179015771485865 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "70 loss:  0.00045716739259660244 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "71 loss:  0.00045264000073075294 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "72 loss:  0.00044816042645834386 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "73 loss:  0.00044387145317159593 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "74 loss:  0.00043965395889244974 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "75 loss:  0.00043562715291045606 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "76 loss:  0.0004317908897064626 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "77 loss:  0.00042814522748813033 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "78 loss:  0.00042476164526306093 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "79 loss:  0.00042147329077124596 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "80 loss:  0.0004184232675470412 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "81 loss:  0.00041542077087797225 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "82 loss:  0.0004125611740164459 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "83 loss:  0.0004097731434740126 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "84 loss:  0.00040708031156100333 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "85 loss:  0.0004044590168632567 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "86 loss:  0.00040178996277973056 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "87 loss:  0.00039926389581523836 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "88 loss:  0.0003966662916354835 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "89 loss:  0.00039416406070813537 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "90 loss:  0.00039170944364741445 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "91 loss:  0.0003893262764904648 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "92 loss:  0.00038701461744494736 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "93 loss:  0.00038470292929559946 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "94 loss:  0.0003825580351985991 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "95 loss:  0.00038038933416828513 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "96 loss:  0.0003782682470045984 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "97 loss:  0.0003761710540857166 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "98 loss:  0.00037419298314489424 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n",
            "99 loss:  0.00037219104706309736 prediction:  [[4 4 3 2 0]] true Y:  [[4, 4, 3, 2, 0]] prediction str:  pple!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 더 많은 데이터로 학습한 문자 단위 RNN (`Char RNN`)"
      ],
      "metadata": {
        "id": "c30XZ_bg2O2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "98-kZTSa2PWM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = (\"if you want to build a ship, don't drum up people together to \"\n",
        "            \"collect wood and don't assign them tasks and work, but rather \"\n",
        "            \"teach them to long for the endless immensity of the sea.\")\n",
        "\n",
        "char_set = list(set(sentence)) # 중복을 제거한 문자 집합\n",
        "char_dic = {c: i for i, c in enumerate(char_set)} # 각 문자에 고유한 정수 인코딩\n",
        "\n",
        "print(char_dic) # 공백도 하나의 원소가 된다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWSoR5KJ2PrJ",
        "outputId": "4e647c4f-3385-494c-92cf-5842f5551b99"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n': 0, 'r': 1, 'c': 2, 'w': 3, ' ': 4, ',': 5, 'm': 6, 'l': 7, 'a': 8, 'o': 9, '.': 10, 'e': 11, 's': 12, \"'\": 13, 'd': 14, 'i': 15, 'p': 16, 'y': 17, 'b': 18, 'u': 19, 'g': 20, 'k': 21, 't': 22, 'h': 23, 'f': 24}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(char_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC4Yd-gQbev2",
        "outputId": "ca419968-013b-43d9-bb18-0a1dad74c4af"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['n', 'r', 'c', 'w', ' ', ',', 'm', 'l', 'a', 'o', '.', 'e', 's', \"'\", 'd', 'i', 'p', 'y', 'b', 'u', 'g', 'k', 't', 'h', 'f']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dic_size = len(char_dic) # 매 시점마다 들어갈 입력의 크기_입력은 원-핫 벡터로 사용\n",
        "print('문자 집합의 크기 : {}'.format(dic_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWTrUAn-bEqM",
        "outputId": "100888a0-b91b-467b-a022-c7fd4b510b1b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 집합의 크기 : 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "hidden_size = dic_size # hidden state 크기를 input 크기로 줬는데, 다른 값을 선택해도 무방\n",
        "sequence_length = 10 # 임의로 설정 / 앞서 만든 샘플을 10개 단위로 끊어서 샘플을 만들 예정\n",
        "learning_rate = 0.1\n",
        "\n",
        "x_data = []\n",
        "y_data = []\n",
        "\n",
        "\"\"\"\n",
        "샘플인 long sentence를 sequence_length(=10) 단위만큼 잘라서\n",
        "윈도우(of size 1)를 이동해 x_data, y_data 생성\n",
        "\"\"\"\n",
        "for i in range(0, len(sentence) - sequence_length):\n",
        "    x_str = sentence[i:i + sequence_length]\n",
        "    y_str = sentence[i + 1:i + sequence_length + 1]\n",
        "    print(i, x_str, '->', y_str)\n",
        "\n",
        "    x_data.append([char_dic[c] for c in x_str]) # x str to idx\n",
        "    y_data.append([char_dic[c] for c in y_str]) # y str to idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VwrOF7dbFyk",
        "outputId": "08768163-7d22-4d4f-b8fa-e73a7eb0c2fd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 if you wan -> f you want\n",
            "1 f you want ->  you want \n",
            "2  you want  -> you want t\n",
            "3 you want t -> ou want to\n",
            "4 ou want to -> u want to \n",
            "5 u want to  ->  want to b\n",
            "6  want to b -> want to bu\n",
            "7 want to bu -> ant to bui\n",
            "8 ant to bui -> nt to buil\n",
            "9 nt to buil -> t to build\n",
            "10 t to build ->  to build \n",
            "11  to build  -> to build a\n",
            "12 to build a -> o build a \n",
            "13 o build a  ->  build a s\n",
            "14  build a s -> build a sh\n",
            "15 build a sh -> uild a shi\n",
            "16 uild a shi -> ild a ship\n",
            "17 ild a ship -> ld a ship,\n",
            "18 ld a ship, -> d a ship, \n",
            "19 d a ship,  ->  a ship, d\n",
            "20  a ship, d -> a ship, do\n",
            "21 a ship, do ->  ship, don\n",
            "22  ship, don -> ship, don'\n",
            "23 ship, don' -> hip, don't\n",
            "24 hip, don't -> ip, don't \n",
            "25 ip, don't  -> p, don't d\n",
            "26 p, don't d -> , don't dr\n",
            "27 , don't dr ->  don't dru\n",
            "28  don't dru -> don't drum\n",
            "29 don't drum -> on't drum \n",
            "30 on't drum  -> n't drum u\n",
            "31 n't drum u -> 't drum up\n",
            "32 't drum up -> t drum up \n",
            "33 t drum up  ->  drum up p\n",
            "34  drum up p -> drum up pe\n",
            "35 drum up pe -> rum up peo\n",
            "36 rum up peo -> um up peop\n",
            "37 um up peop -> m up peopl\n",
            "38 m up peopl ->  up people\n",
            "39  up people -> up people \n",
            "40 up people  -> p people t\n",
            "41 p people t ->  people to\n",
            "42  people to -> people tog\n",
            "43 people tog -> eople toge\n",
            "44 eople toge -> ople toget\n",
            "45 ople toget -> ple togeth\n",
            "46 ple togeth -> le togethe\n",
            "47 le togethe -> e together\n",
            "48 e together ->  together \n",
            "49  together  -> together t\n",
            "50 together t -> ogether to\n",
            "51 ogether to -> gether to \n",
            "52 gether to  -> ether to c\n",
            "53 ether to c -> ther to co\n",
            "54 ther to co -> her to col\n",
            "55 her to col -> er to coll\n",
            "56 er to coll -> r to colle\n",
            "57 r to colle ->  to collec\n",
            "58  to collec -> to collect\n",
            "59 to collect -> o collect \n",
            "60 o collect  ->  collect w\n",
            "61  collect w -> collect wo\n",
            "62 collect wo -> ollect woo\n",
            "63 ollect woo -> llect wood\n",
            "64 llect wood -> lect wood \n",
            "65 lect wood  -> ect wood a\n",
            "66 ect wood a -> ct wood an\n",
            "67 ct wood an -> t wood and\n",
            "68 t wood and ->  wood and \n",
            "69  wood and  -> wood and d\n",
            "70 wood and d -> ood and do\n",
            "71 ood and do -> od and don\n",
            "72 od and don -> d and don'\n",
            "73 d and don' ->  and don't\n",
            "74  and don't -> and don't \n",
            "75 and don't  -> nd don't a\n",
            "76 nd don't a -> d don't as\n",
            "77 d don't as ->  don't ass\n",
            "78  don't ass -> don't assi\n",
            "79 don't assi -> on't assig\n",
            "80 on't assig -> n't assign\n",
            "81 n't assign -> 't assign \n",
            "82 't assign  -> t assign t\n",
            "83 t assign t ->  assign th\n",
            "84  assign th -> assign the\n",
            "85 assign the -> ssign them\n",
            "86 ssign them -> sign them \n",
            "87 sign them  -> ign them t\n",
            "88 ign them t -> gn them ta\n",
            "89 gn them ta -> n them tas\n",
            "90 n them tas ->  them task\n",
            "91  them task -> them tasks\n",
            "92 them tasks -> hem tasks \n",
            "93 hem tasks  -> em tasks a\n",
            "94 em tasks a -> m tasks an\n",
            "95 m tasks an ->  tasks and\n",
            "96  tasks and -> tasks and \n",
            "97 tasks and  -> asks and w\n",
            "98 asks and w -> sks and wo\n",
            "99 sks and wo -> ks and wor\n",
            "100 ks and wor -> s and work\n",
            "101 s and work ->  and work,\n",
            "102  and work, -> and work, \n",
            "103 and work,  -> nd work, b\n",
            "104 nd work, b -> d work, bu\n",
            "105 d work, bu ->  work, but\n",
            "106  work, but -> work, but \n",
            "107 work, but  -> ork, but r\n",
            "108 ork, but r -> rk, but ra\n",
            "109 rk, but ra -> k, but rat\n",
            "110 k, but rat -> , but rath\n",
            "111 , but rath ->  but rathe\n",
            "112  but rathe -> but rather\n",
            "113 but rather -> ut rather \n",
            "114 ut rather  -> t rather t\n",
            "115 t rather t ->  rather te\n",
            "116  rather te -> rather tea\n",
            "117 rather tea -> ather teac\n",
            "118 ather teac -> ther teach\n",
            "119 ther teach -> her teach \n",
            "120 her teach  -> er teach t\n",
            "121 er teach t -> r teach th\n",
            "122 r teach th ->  teach the\n",
            "123  teach the -> teach them\n",
            "124 teach them -> each them \n",
            "125 each them  -> ach them t\n",
            "126 ach them t -> ch them to\n",
            "127 ch them to -> h them to \n",
            "128 h them to  ->  them to l\n",
            "129  them to l -> them to lo\n",
            "130 them to lo -> hem to lon\n",
            "131 hem to lon -> em to long\n",
            "132 em to long -> m to long \n",
            "133 m to long  ->  to long f\n",
            "134  to long f -> to long fo\n",
            "135 to long fo -> o long for\n",
            "136 o long for ->  long for \n",
            "137  long for  -> long for t\n",
            "138 long for t -> ong for th\n",
            "139 ong for th -> ng for the\n",
            "140 ng for the -> g for the \n",
            "141 g for the  ->  for the e\n",
            "142  for the e -> for the en\n",
            "143 for the en -> or the end\n",
            "144 or the end -> r the endl\n",
            "145 r the endl ->  the endle\n",
            "146  the endle -> the endles\n",
            "147 the endles -> he endless\n",
            "148 he endless -> e endless \n",
            "149 e endless  ->  endless i\n",
            "150  endless i -> endless im\n",
            "151 endless im -> ndless imm\n",
            "152 ndless imm -> dless imme\n",
            "153 dless imme -> less immen\n",
            "154 less immen -> ess immens\n",
            "155 ess immens -> ss immensi\n",
            "156 ss immensi -> s immensit\n",
            "157 s immensit ->  immensity\n",
            "158  immensity -> immensity \n",
            "159 immensity  -> mmensity o\n",
            "160 mmensity o -> mensity of\n",
            "161 mensity of -> ensity of \n",
            "162 ensity of  -> nsity of t\n",
            "163 nsity of t -> sity of th\n",
            "164 sity of th -> ity of the\n",
            "165 ity of the -> ty of the \n",
            "166 ty of the  -> y of the s\n",
            "167 y of the s ->  of the se\n",
            "168  of the se -> of the sea\n",
            "169 of the sea -> f the sea.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 170개의 샘플이 생성됨\n",
        "print('x_data 개수: ', len(x_data), '& y_data 개수: ', len(y_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw5EK5ykbGCU",
        "outputId": "194a8105-e270-4338-d352-bf690233a727"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data 개수:  170 & y_data 개수:  170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list형이라 np.shape(리스트 명) 으로 shape을 보자\n",
        "print(np.shape(x_data), ' & ', np.shape(y_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwLLYTr679kk",
        "outputId": "c4e33342-3675-4ffe-f6df-05a35a052846"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(170, 10)  &  (170, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_data[0]) # 첫번째 샘플의 입력 데이터 / if you wan에 해당\n",
        "print(y_data[0]) # 첫번째 샘플의 레이블 데이터 /  f you want에 해당"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C_7XK1jcKYi",
        "outputId": "8f5d027e-ee4c-4b8c-9ed9-81febb457fb3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15, 24, 4, 17, 9, 19, 4, 3, 8, 0]\n",
            "[24, 4, 17, 9, 19, 4, 3, 8, 0, 22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = [np.eye(dic_size)[x] for x in x_data] # 입력 시퀀스에 원-핫 인코딩 수행 / x 데이터는 원-핫 인코딩\n",
        "X = torch.FloatTensor(x_one_hot) # 텐서로 변환\n",
        "Y = torch.LongTensor(y_data)\n",
        "\n",
        "# 10은 sequence_length, 25는 char_dic 크기, 즉 전체 sentence에 사용된 문자의 개수\n",
        "print('훈련 데이터의 크기: {}'.format(X.shape))\n",
        "print('레이블의 크기: {}'.format(Y.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N1hp3zJ0gzS",
        "outputId": "7d7997c9-6a5a-4f16-e77a-006e37687d05"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기: torch.Size([170, 10, 25])\n",
            "레이블의 크기: torch.Size([170, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot[0]\n",
        "print(X[0].shape, Y[0].shape) # 0 if you wan -> f you want"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv22SZAY-R8q",
        "outputId": "53336ecc-519a-486e-8cef-460ce7e8eae1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 25]) torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqlbjfvi7OXt",
        "outputId": "d634ea8d-4ff1-45cb-8509-62dc692aee4c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_one_hot[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xPJtvA0-wbb",
        "outputId": "44c5dc77-1666-49b2-df24-4a4b34b47b62"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  1.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫번째 샘플의 원-핫 인코딩 결과\n",
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PRIdb5OcKmq",
        "outputId": "cb7c0a7f-2470-401c-dfac-469859c1151f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor([\n",
        "[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], # i\n",
        "\n",
        "[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], # f\n",
        "\n",
        "[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], # 공백\n",
        "\n",
        "[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], # y\n",
        "\n",
        "[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], # o\n",
        "\n",
        "[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], # y\n",
        "\n",
        "[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], # 공백\n",
        "\n",
        "[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], # w\n",
        "\n",
        "[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], # a\n",
        "\n",
        "[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) # n\n",
        "\n"
      ],
      "metadata": {
        "id": "levkqRig1QQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블 데이터의 첫번째 샘플의 원-핫 인코딩 결과\n",
        "# f you want에 해당\n",
        "print(Y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jyvcgtScLB8",
        "outputId": "0c69e052-7a2a-4274-f700-84574b95b80c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([24,  4, 17,  9, 19,  4,  3,  8,  0, 22])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) 모델 구현하기"
      ],
      "metadata": {
        "id": "RKIvn12Z4rzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "vannila RNN w/ 2 layers\n",
        "\"\"\"\n",
        "class Net(torch.nn.Module):\n",
        "    # 현재 hidden_size는 dic_size와 동일\n",
        "    def __init__(self, input_dim, hidden_dim, layers):\n",
        "        super(Net, self).__init__()\n",
        "        self.rnn = torch.nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _status = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "net = Net(dic_size, hidden_size, 2) # 층 2개 사용"
      ],
      "metadata": {
        "id": "X1s7uMrf4iwb"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKZ2Q6bJ4Pri",
        "outputId": "752ffe39-0181-4024-e3b4-0e1e31e9a40b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (rnn): RNN(25, 25, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=25, out_features=25, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "비용 함수와 옵티마이저\n",
        "\"\"\"\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), learning_rate)\n",
        "\n",
        "outputs = net(X)\n",
        "print(outputs.shape) # 3D 텐서, [170, 10, 25] 크기로, 배치 차원 x 시점(timesteps) x 출력 크기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjaZpEB94P6M",
        "outputId": "a1e82fb5-3fc1-494d-8caf-5f947ced16ae"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([170, 10, 25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "나중에 정확도를 측청할 때, 이를 모두 펼쳐서 계산하는데\n",
        "이때 view를 사용하여 배치 차원과 시점 차원을 하나로 만든다.\n",
        "\"\"\"\n",
        "print(outputs.view(-1, dic_size).shape) # 2D 텐서로 변환"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhBDah-OcKzs",
        "outputId": "30b909fc-ed60-490a-8de6-387160648c80"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1700, 25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y.shape) # 레이블 데이터의 크기\n",
        "print(Y.view(-1).shape)\n",
        "print(Y.view(-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wC1aaImCIK6",
        "outputId": "e94efbb1-7642-446f-d9d0-f92a0179ba4d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([170, 10])\n",
            "torch.Size([1700])\n",
            "tensor([24,  4, 17,  ..., 11,  8, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X) # (170, 10, 25) 크기를 가진 텐서를 매 에포크마다 모델의 입력으로 사용\n",
        "    loss = criterion(outputs.view(-1, dic_size), Y.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    results = outputs.argmax(dim=2) # results의 텐서 크기는 (170, 10)\n",
        "    predict_str = \"\"\n",
        "    for j, result in enumerate(results):\n",
        "        if j == 0: # 처음에는 예측 결과를 전부 가져오고\n",
        "            predict_str += ''.join([char_set[t] for t in result])\n",
        "        else: # 그 다음부턴 마지막 글자만 추가\n",
        "            predict_str += char_set[result[-1]]\n",
        "\n",
        "print(predict_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqiv7a9y6qES",
        "outputId": "f565a81a-9d82-4f1a-df41-e15a96237f99"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "m you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwDf5SEO6qgE",
        "outputId": "e1e5898b-c838-4a9a-d203-a3e9febec8f0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([170, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PaMswCuf6rZ_"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z6r_QxNX6rMp"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QWjDGnY86rBy"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MD7qIVnz6qvl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3kCOFu8q4PYN"
      },
      "execution_count": 39,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}